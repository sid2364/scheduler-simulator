{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib tqdm numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tqdm import tqdm\n",
    "from multiprocessor.scheduler import MultiprocessorSchedulerType\n",
    "from multiprocessor.partitioner import FirstFit, NextFit, BestFit, WorstFit\n",
    "\n",
    "# self-written modules\n",
    "from utils.metrics import MultiprocessorFeasibility, calculate_success_rate\n",
    "from utils.plotters import plot_average_execution_time\n",
    "from utils.parse import parse_task_file\n",
    "from multiprocessor.feasibility.review import review_task_sets_in_parallel_multi\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate feasibility ratio by parameter\n",
    "def calculate_feasibility_ratio(schedule_stats):\n",
    "    feasible = schedule_stats.get(MultiprocessorFeasibility.FEASIBLE_SHORTCUT, 0) + \\\n",
    "               schedule_stats.get(MultiprocessorFeasibility.FEASIBLE_SIMULATION, 0)\n",
    "    total = feasible + schedule_stats.get(MultiprocessorFeasibility.NOT_SCHEDULABLE_BY_A_SHORTCUT, 0) + \\\n",
    "            schedule_stats.get(MultiprocessorFeasibility.NOT_SCHEDULABLE_BY_A_SIMULATION, 0)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    return feasible / total * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process task sets for Plot 1 and 2 (by number of tasks)\n",
    "\n",
    "def average_execution_time_by_workers(config, folder_name):\n",
    "    \"\"\"\n",
    "    Process task sets organized by number of tasks (like in 4-tasks, 10-tasks).\n",
    "    \"\"\"\n",
    "    # subfolders = sorted([f for f in Path(folder_name).iterdir() if f.is_dir()], key=lambda x: int(x.name))\n",
    "    # print(subfolders)\n",
    "    execution_times = []\n",
    "\n",
    "    workers = config[\"number_of_workers\"]\n",
    "\n",
    "    for worker_quantity in workers:\n",
    "        start_time = time()\n",
    "\n",
    "        print(f\"Executing with: {worker_quantity} workers.\")\n",
    "        #for subfolder in subfolders:\n",
    "        #print(f\"Subfolder: {subfolder}\")\n",
    "        num_tasks = 100\n",
    "        #print(f\"\\nProcessing {num_tasks} tasks in {subfolder}\")\n",
    "        print(f\"Evaluating algorithm: {config[\"alg\"].name}\")\n",
    "        schedule_stats = review_task_sets_in_parallel_multi(algorithm=config[\"alg\"],\n",
    "                                                        folder_name=folder_name,\n",
    "                                                        num_processors=config[\"processors\"],\n",
    "                                                        #num_clusters=config[\"clusters\"],\n",
    "                                                        heuristic=config[\"heuristic\"],\n",
    "                                                        number_of_workers=worker_quantity)\n",
    "            # success_rate = calculate_success_rate(schedule_stats) #TODO execution time\n",
    "            # execution_times[num_tasks] = success_rate\n",
    "        end_time = time() - start_time\n",
    "        print(end_time)\n",
    "\n",
    "        execution_times.append(\n",
    "            {\n",
    "                \"workers\": worker_quantity,\n",
    "                \"time\": end_time\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return execution_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing with: 1 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 1\n",
      "Total files considered: 1000\n",
      "36.801666498184204\n",
      "Executing with: 2 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 2\n",
      "Total files considered: 1000\n",
      "37.88992881774902\n",
      "Executing with: 3 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 3\n",
      "Total files considered: 1000\n",
      "37.68984580039978\n",
      "Executing with: 4 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 4\n",
      "Total files considered: 1000\n",
      "39.10228085517883\n",
      "Executing with: 5 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 5\n",
      "Total files considered: 1000\n",
      "39.5596764087677\n",
      "Executing with: 6 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 6\n",
      "Total files considered: 1000\n",
      "39.73914670944214\n",
      "Executing with: 7 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 7\n",
      "Total files considered: 1000\n",
      "41.41538953781128\n",
      "Executing with: 8 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 0\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "41.91704821586609\n",
      "Executing with: 9 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 1\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "41.59058737754822\n",
      "Executing with: 10 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 2\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "36.64422416687012\n",
      "Executing with: 11 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 3\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "34.364858627319336\n",
      "Executing with: 12 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 4\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.72035479545593\n",
      "Executing with: 13 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 5\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.61218881607056\n",
      "Executing with: 14 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 6\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.504170179367065\n",
      "Executing with: 15 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 7\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.40747356414795\n",
      "Executing with: 16 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 8\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.65013146400452\n",
      "Executing with: 17 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 9\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.39999604225159\n",
      "Executing with: 18 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 10\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.6957905292511\n",
      "Executing with: 19 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 11\n",
      "Number of workers for the algorithms: 8\n",
      "Total files considered: 1000\n",
      "33.08541536331177\n",
      "Executing with: 20 workers.\n",
      "Evaluating algorithm: PARTITIONED_EDF\n",
      "Number of workers for the task sets: 12\n",
      "Number of workers for the algorithms: 8\n"
     ]
    }
   ],
   "source": [
    "def get_workers_range(from_val, to_val):\n",
    "    return list(range(from_val, to_val + 1))\n",
    "\n",
    "config_to_evaluate = {\n",
    "        \"alg\": MultiprocessorSchedulerType.PARTITIONED_EDF,\n",
    "        \"heuristic\": BestFit(decreasing_utilisation=True, verbose=False),\n",
    "        \"sorting\": 'du',\n",
    "        \"processors\": 8,\n",
    "        #\"clusters\": 4,\n",
    "        \"number_of_workers\": get_workers_range(1, 20)\n",
    "    }\n",
    "# python3 main.py tasksets-multiprocessor 8 partitioned -H bf -s du\n",
    "\n",
    "results = average_execution_time_by_workers(config=config_to_evaluate, folder_name=\"tasksets-multiprocessor/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(f\"Time taken for {result[\"workers\"]} workers: {result[\"time\"]}\")\n",
    "\n",
    "workers = [result[\"workers\"] for result in results]\n",
    "times = [result[\"time\"] for result in results]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(workers, times, color='teal', width=0.6)\n",
    "plt.xlabel('Number of Workers')\n",
    "plt.ylabel('Time Taken (seconds)')\n",
    "plt.title('Time Taken vs Number of Workers')\n",
    "plt.xticks(workers)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Learning Dynamics Env)",
   "language": "python",
   "name": "learning_dynamics_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
